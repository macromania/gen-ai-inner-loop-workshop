{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Get the shell\n",
    "shell = sys.executable\n",
    "print(\"Shell:\", shell)\n",
    "\n",
    "# Get the profile\n",
    "profile = sys.argv[0]\n",
    "print(\"Profile:\", profile)\n",
    "\n",
    "%alias python python3\n",
    "\n",
    "print(\"python xcode profile version\")\n",
    "!python --version\n",
    "\n",
    "print(\"python kernel version\")\n",
    "!python3 --version\n",
    "\n",
    "print(\"loading dotenv extension...\")\n",
    "%load_ext dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"load environment variables from .env file\")\n",
    "\n",
    "%reload_ext dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "loaded_env = load_dotenv(\"../../.env\")\n",
    "print(\"Loaded .env file:\", loaded_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages\n",
    "To run the code, install the following packages. Please use the latest stable version by running pip install azure-search-documents. This sample currently uses version 11.4.0 and openai version 1.3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents \n",
    "! pip install openai \n",
    "! pip install tenacity\n",
    "! pip install pandas\n",
    "! pip install azure-ai-documentintelligence\n",
    "! pip install azure-ai-formrecognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import json  \n",
    "import openai\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient, SearchIndexingBufferedSender  \n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.ai.formrecognizer import AnalyzeResult\n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSearch,\n",
    "    VectorSearch,  \n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,  \n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchProfile,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    ExhaustiveKnnParameters,\n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    VectorSearch,  \n",
    "    HnswParameters,  \n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    ") \n",
    "from openai.types.chat import (\n",
    "    ChatCompletionAssistantMessageParam,\n",
    "    ChatCompletionContentPartParam,\n",
    "    ChatCompletionMessageParam,\n",
    "    ChatCompletionSystemMessageParam,\n",
    "    ChatCompletionUserMessageParam,\n",
    ")\n",
    "\n",
    "# Configure environment variables  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\") \n",
    "index_name = \"pdfindex\" #os.getenv(\"AZURE_SEARCH_INDEX\") \n",
    "key = os.getenv(\"AZURE_SEARCH_API_KEY\") \n",
    "open_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "open_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "open_api_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "form_recognizer_key = os.getenv(\"AZURE_FORMRECOGNIZER_API_KEY\")\n",
    "form_recognizer_endpoint = os.getenv(\"AZURE_FORMRECOGNIZER_ENDPOINT\")\n",
    "\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure AI Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = os.getenv(\"AZURE_OPENAI_EMB_DEPLOYMENT\")\n",
    "model_name = os.getenv(\"AZURE_OPENAI_EMB_MODEL_NAME\")\n",
    "\n",
    "print(\"Deployment Name:\", deployment_name)\n",
    "print(\"Model Name:\", model_name)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = open_api_key,  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = open_api_endpoint\n",
    ")\n",
    "\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "    endpoint=form_recognizer_endpoint, credential=AzureKeyCredential(form_recognizer_key)\n",
    ")\n",
    "\n",
    "shell_report_url = \"https://reports.shell.com/sustainability-report/2022/_assets/downloads/shell-sustainability-report-2022.pdf\"\n",
    "\n",
    "print(f\"Beginning analyze document for {shell_report_url}\")\n",
    "analyze_poller = document_analysis_client.begin_analyze_document_from_url(\"prebuilt-read\", shell_report_url)\n",
    "analyze_result: AnalyzeResult = analyze_poller.result()\n",
    "\n",
    "print(\"Document Analyze Result completed\")\n",
    "\n",
    "analysed_pages = []\n",
    "\n",
    "for page in analyze_result.pages:\n",
    "    parsed_page = {\n",
    "      \"pageNumber\": f\"{page.page_number}\",\n",
    "      \"content\": \"\"\n",
    "    }\n",
    "    for word in page.words:\n",
    "        parsed_page[\"content\"] += word.content + \" \"\n",
    "    \n",
    "    analysed_pages.append(parsed_page)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text, model):\n",
    "    try:\n",
    "        return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e) \n",
    "\n",
    "print(\"Generating embeddings for content\")\n",
    "for page in analysed_pages:\n",
    "    pageNumber = page['pageNumber']\n",
    "    content = page['content']\n",
    "    content_embeddings = generate_embeddings(content, deployment_name)\n",
    "    page['contentVector'] = content_embeddings\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"../output/docVectors.json\", \"w\") as f:\n",
    "    print(\"Writing docVectors.json\")\n",
    "    json.dump(analysed_pages, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"pageNumber\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index_client.delete_index(index_name)\n",
    "\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload some documents to the index\n",
    "with open('../output/docVectors.json', 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search\n",
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"operational process safety events in 2022?\"\n",
    "\n",
    "print(\"Asking question:\", query)\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "\n",
    "# Generate the query vector using text embeddings from the OpenAI API\n",
    "vector_query = VectorizedQuery(vector=generate_embeddings(query, model=deployment_name), k_nearest_neighbors=7, fields=\"contentVector\")\n",
    "\n",
    "print(\"Searching...\")\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"pageNumber\", \"content\"],\n",
    ")  \n",
    "\n",
    "search_result = \"\"\n",
    "  \n",
    "for result in results:  \n",
    "    search_result += f\"Page: {result['pageNumber']}\\n\"\n",
    "    search_result += f\"Content: {result['content']}\\n\"\n",
    "    search_result += f\"Score: {result['@search.score']}\\n\\n\"\n",
    "    \n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crate Chat Completion\n",
    "\n",
    "Using the search result as user content, we can use the OpenAI API to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model_name = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\")\n",
    "print(\"Chat Model Name:\", chat_model_name)\n",
    "\n",
    "system_chat_template = (\n",
    "        \"You are an intelligent assistant helping Contoso Inc employees for their sustainability report questions. \"\n",
    "        + \"Use 'you' to refer to the individual asking the questions even if they ask with 'I'. \"\n",
    "        + \"Answer the following question using only the data provided in the sources below. \"\n",
    "        + \"For tabular information return it as an html table. Do not return markdown format. \"\n",
    "        + \"Include page source as citation\"\n",
    "        + \"Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. \"\n",
    "        + \"If you cannot answer using the sources below, say you don't know. Use below example to answer\"\n",
    "    )\n",
    "\n",
    "def create_message(role: str, content: str):\n",
    "    \"\"\"\n",
    "    Inserts a message into the conversation at the specified index,\n",
    "    or at index 1 (after system message) if no index is specified.\n",
    "    Args:\n",
    "        role (str): The role of the message sender (either \"user\", \"system\", or \"assistant\").\n",
    "        content (str | List[ChatCompletionContentPartParam]): The content of the message.\n",
    "        index (int): The index at which to insert the message.\n",
    "    \"\"\"\n",
    "    message: ChatCompletionMessageParam\n",
    "    if role == \"user\":\n",
    "        return ChatCompletionUserMessageParam(role=\"user\", content=unicodedata.normalize(\"NFC\", content))\n",
    "    elif role == \"system\" and isinstance(content, str):\n",
    "        return ChatCompletionSystemMessageParam(role=\"system\", content=unicodedata.normalize(\"NFC\", content))\n",
    "    elif role == \"assistant\" and isinstance(content, str):\n",
    "        return ChatCompletionAssistantMessageParam(role=\"assistant\", content=unicodedata.normalize(\"NFC\", content))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid role: {role}\")\n",
    "\n",
    "\n",
    "messages: list[ChatCompletionMessageParam] = []\n",
    "\n",
    "user_content = f\"{query} \\n Sources: \\n {search_result}\"\n",
    "messages.append(create_message(\"user\", user_content))\n",
    "messages.append(create_message(\"system\", system_chat_template))\n",
    "\n",
    "print(\"Chat completion messages:\", messages)\n",
    "\n",
    "print(\"Creating chat completion...\")\n",
    "chat_completion = client.chat.completions.create(\n",
    "                # Azure Open AI takes the deployment name as the model name\n",
    "                model=chat_model_name,\n",
    "                messages=messages,\n",
    "                temperature=0.3,\n",
    "                max_tokens=1024,\n",
    "                n=1,\n",
    "            )\n",
    "\n",
    "\n",
    "print(chat_completion)\n",
    "\n",
    "print(\"Chat completion completed\")\n",
    "print(\"Chat completion result:\", chat_completion.choices[0].message.content)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
